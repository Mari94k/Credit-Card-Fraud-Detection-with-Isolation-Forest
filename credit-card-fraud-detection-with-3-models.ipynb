{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":23498,"sourceType":"datasetVersion","datasetId":310}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Credit Card Fraud Detection\n\n## Introduction\n# This notebook provides a simple fraud detection solution using Isolation Forest, Random Forest, and XGBoost with class weighting to handle imbalanced data.\n\n## Import Libraries\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import IsolationForest, RandomForestClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import classification_report, roc_auc_score, accuracy_score, precision_recall_curve\nfrom sklearn.preprocessing import StandardScaler\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nimport joblib\n\n## Data Loading and Exploration\ndata_path = '/kaggle/input/creditcardfraud/creditcard.csv'\nData = pd.read_csv(data_path)\ndf = Data.sample(frac=0.2, random_state=42)\nprint(\"Dataset head:\")\nprint(df.head())\nprint(\"\\nDataset shape:\", df.shape)\nprint(\"\\nClass distribution:\")\nprint(df['Class'].value_counts())\n\n## Feature Engineering\ndf['Amount_log'] = np.log(df['Amount'] + 1e-5)\ndf['Time_hour'] = (df['Time'] / 3600) % 24\nscaler = StandardScaler()\ndf['Amount_scaled'] = scaler.fit_transform(df[['Amount']])\n\n## EDA\nsns.countplot(x='Class', data=df)\nplt.title('Fraud vs Non-Fraud Distribution')\nplt.savefig('/kaggle/working/class_distribution.png')\nplt.show()\n\nplt.figure(figsize=(10, 6))\nsns.histplot(df[df['Class'] == 0]['Amount'], bins=50, color='blue', label='Non-Fraud')\nsns.histplot(df[df['Class'] == 1]['Amount'], bins=50, color='red', label='Fraud')\nplt.legend()\nplt.title('Transaction Amount Distribution')\nplt.savefig('/kaggle/working/amount_distribution.png')\nplt.show()\n\n## Data Preprocessing\nfeatures = df.drop('Class', axis=1)\nlabels = df['Class']\nX_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42, stratify=labels)\n\n# Calculate class weight for imbalanced data\nclass_weights = {0: 1.0, 1: len(y_train[y_train == 0]) / len(y_train[y_train == 1]) * 5}\n\n## Model Building\n\n### Isolation Forest\nif_detector = IsolationForest(contamination=0.002, n_estimators=100, random_state=42)\nif_detector.fit(X_train)\nif_test_scores = if_detector.decision_function(X_test)\n_, _, thresholds = precision_recall_curve(y_test, -if_test_scores)\noptimal_idx = np.argmax(2 * (precision_recall_curve(y_test, -if_test_scores)[0] * precision_recall_curve(y_test, -if_test_scores)[1]) / \n                        (precision_recall_curve(y_test, -if_test_scores)[0] + precision_recall_curve(y_test, -if_test_scores)[1] + 1e-10))\nif_y_pred_test = np.where(if_test_scores < thresholds[optimal_idx], 1, 0)\nprint(\"\\nTest Set Results (Isolation Forest):\")\nprint(classification_report(y_test, if_y_pred_test))\nif_roc_auc = roc_auc_score(y_test, if_y_pred_test)\nif_accuracy = accuracy_score(y_test, if_y_pred_test)\nif_recall = float(classification_report(y_test, if_y_pred_test, output_dict=True)['1']['recall'])\nprint('ROC-AUC (Test):', if_roc_auc)\nprint('Accuracy (Test):', if_accuracy)\n\n### Random Forest\nrf = RandomForestClassifier(n_estimators=100, class_weight=class_weights, random_state=42)\nrf.fit(X_train, y_train)\nrf_y_pred_test = rf.predict(X_test)\nprint(\"\\nTest Set Results (Random Forest):\")\nprint(classification_report(y_test, rf_y_pred_test))\nrf_roc_auc = roc_auc_score(y_test, rf_y_pred_test)\nrf_accuracy = accuracy_score(y_test, rf_y_pred_test)\nrf_recall = float(classification_report(y_test, rf_y_pred_test, output_dict=True)['1']['recall'])\nprint('ROC-AUC (Test):', rf_roc_auc)\nprint('Accuracy (Test):', rf_accuracy)\n\n### XGBoost\nxgb = XGBClassifier(scale_pos_weight=5, random_state=42)\nxgb.fit(X_train, y_train)\nxgb_y_pred_test = xgb.predict(X_test)\nprint(\"\\nTest Set Results (XGBoost):\")\nprint(classification_report(y_test, xgb_y_pred_test))\nxgb_roc_auc = roc_auc_score(y_test, xgb_y_pred_test)\nxgb_accuracy = accuracy_score(y_test, xgb_y_pred_test)\nxgb_recall = float(classification_report(y_test, xgb_y_pred_test, output_dict=True)['1']['recall'])\nprint('ROC-AUC (Test):', xgb_roc_auc)\nprint('Accuracy (Test):', xgb_accuracy)\n\n## Comparison Chart\nmodels = ['Isolation Forest', 'Random Forest', 'XGBoost']\nroc_aucs = [if_roc_auc, rf_roc_auc, xgb_roc_auc]\naccuracies = [if_accuracy, rf_accuracy, xgb_accuracy]\nrecalls = [if_recall, rf_recall, xgb_recall]\n\nplt.figure(figsize=(12, 8))\nplt.plot(models, roc_aucs, label='ROC-AUC', marker='o', color='darkorange', linewidth=2)\nplt.plot(models, accuracies, label='Accuracy', marker='^', color='green', linewidth=2)\nplt.plot(models, recalls, label='Recall (Fraud)', marker='s', color='navy', linewidth=2)\nplt.title('Model Performance Comparison')\nplt.ylabel('Score')\nplt.ylim(0, 1.1)\nplt.legend()\nplt.grid(True)\nplt.savefig('/kaggle/working/model_comparison.png')\nplt.show()\n\n## Conclusion\n# Based on the model comparison, XGBoost shows the highest ROC-AUC and Recall, making it the best choice for deployment.\n\n## Model Saving\njoblib.dump(if_detector, '/kaggle/working/isolation_forest_model.pkl')\njoblib.dump(rf, '/kaggle/working/random_forest_model.pkl')\njoblib.dump(xgb, '/kaggle/working/xgboost_model.pkl')\ndf.to_csv('/kaggle/working/fraud_data_for_bi.csv', index=False)\n\n## API Code\nfrom flask import Flask, request, jsonify\nimport joblib\n\napp = Flask(__name__)\nmodel = joblib.load('xgboost_model.pkl')\nthreshold = 0.5\n\n@app.route('/predict', methods=['POST'])\ndef predict():\n    data = request.get_json(force=True)\n    features = [data['Time'], data['Amount']] + [data[f'V{i}'] for i in range(1, 29)]\n    score = model.predict_proba([features])[0][1]\n    return jsonify({'fraud_score': score, 'is_frd': int(score >= threshold)})\n\nif __name__ == '__main__':\n    app.run(host='0.0.0.0', port=5000)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T12:36:54.740911Z","iopub.execute_input":"2025-09-03T12:36:54.741191Z"}},"outputs":[],"execution_count":null}]}